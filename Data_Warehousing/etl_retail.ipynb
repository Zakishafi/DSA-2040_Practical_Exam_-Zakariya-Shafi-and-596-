{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74ae6e25",
   "metadata": {},
   "source": [
    "# DSA 2040 Practical Exam - Section 1: Data Warehousing\n",
    "\n",
    "**Student Name:** Zakariya Shafi \n",
    "**Student ID:** 596 \n",
    "**Date:** December 12, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates the complete **ETL (Extract, Transform, Load)** pipeline for building a Data Warehouse using a **Star Schema** design. The warehouse is designed to support OLAP queries for retail sales analysis.\n",
    "\n",
    "### Objectives:\n",
    "1. **Extract** data from the Online Retail CSV dataset\n",
    "2. **Transform** the data (clean, calculate metrics, simulate current dates)\n",
    "3. **Load** data into an SQLite Data Warehouse\n",
    "4. **Visualize** insights from the warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1871a21",
   "metadata": {},
   "source": [
    "## 1. Import the required libraries\n",
    "We'll use:\n",
    "- `pandas` for data manipulation\n",
    "- `sqlite3` for database operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bb57ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL Process for Online Retail CSV\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efef42b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Extract: Read CSV\n",
    "# -----------------------------\n",
    "def extract_data(filepath):\n",
    "    # Read CSV (Online Retail)\n",
    "    df = pd.read_csv(\"C:/Users/user/DSA2040_End_Sem/Online_Retail.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "    print(f\"Initial rows in CSV: {len(df)}\")\n",
    "\n",
    "    # Convert InvoiceDate to datetime\n",
    "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')\n",
    "\n",
    "    # Drop rows with missing CustomerID\n",
    "    df = df.dropna(subset=['CustomerID'])\n",
    "    print(f\"Rows after dropping missing CustomerID: {len(df)}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b045f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Transform: Clean & Prepare\n",
    "# -----------------------------\n",
    "def transform_data(df):\n",
    "    # Remove outliers (Quantity < 0 or UnitPrice <= 0)\n",
    "    df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n",
    "    print(f\"Rows after removing outliers: {len(df)}\")\n",
    "\n",
    "    # Create TotalSales column\n",
    "    df['TotalSales'] = df['Quantity'] * df['UnitPrice']\n",
    "\n",
    "    # Customer Dimension\n",
    "    customer_dim = df.groupby('CustomerID').agg(\n",
    "        TotalPurchases=('TotalSales', 'sum'),\n",
    "        Country=('Country', 'first')\n",
    "    ).reset_index()\n",
    "    print(f\"CustomerDim rows: {len(customer_dim)}\")\n",
    "\n",
    "    # Time Dimension\n",
    "    df['Year'] = df['InvoiceDate'].dt.year\n",
    "    df['Month'] = df['InvoiceDate'].dt.month\n",
    "    df['Day'] = df['InvoiceDate'].dt.day\n",
    "    time_dim = df[['InvoiceDate', 'Year', 'Month', 'Day']].drop_duplicates().reset_index(drop=True)\n",
    "    print(f\"TimeDim rows: {len(time_dim)}\")\n",
    "\n",
    "    # Filter for sales in last year (Aug 12, 2024 to Aug 12, 2025)\n",
    "    last_year_start = datetime(2024, 8, 12)\n",
    "    last_year_end = datetime(2025, 8, 12)\n",
    "    sales_fact = df[(df['InvoiceDate'] >= last_year_start) & (df['InvoiceDate'] <= last_year_end)]\n",
    "    print(f\"SalesFact rows (last year): {len(sales_fact)}\")\n",
    "\n",
    "    return sales_fact, customer_dim, time_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "198dc5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Load: Insert into SQLite\n",
    "# -----------------------------\n",
    "def load_data(sales_fact, customer_dim, time_dim, db_name='retail_dw.db'):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create tables\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS CustomerDim (\n",
    "            CustomerID INTEGER PRIMARY KEY,\n",
    "            TotalPurchases REAL,\n",
    "            Country TEXT\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS TimeDim (\n",
    "            InvoiceDate TEXT PRIMARY KEY,\n",
    "            Year INTEGER,\n",
    "            Month INTEGER,\n",
    "            Day INTEGER\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS SalesFact (\n",
    "            InvoiceNo TEXT,\n",
    "            StockCode TEXT,\n",
    "            Quantity INTEGER,\n",
    "            UnitPrice REAL,\n",
    "            TotalSales REAL,\n",
    "            CustomerID INTEGER,\n",
    "            InvoiceDate TEXT,\n",
    "            FOREIGN KEY(CustomerID) REFERENCES CustomerDim(CustomerID),\n",
    "            FOREIGN KEY(InvoiceDate) REFERENCES TimeDim(InvoiceDate)\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "    # Insert data\n",
    "    customer_dim.to_sql('CustomerDim', conn, if_exists='replace', index=False)\n",
    "    time_dim.to_sql('TimeDim', conn, if_exists='replace', index=False)\n",
    "    sales_fact.to_sql('SalesFact', conn, if_exists='replace', index=False)\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"Data loaded into {db_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "344f8ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial rows in CSV: 541909\n",
      "Rows after dropping missing CustomerID: 406829\n",
      "Rows after removing outliers: 397884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5600\\2633493936.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TotalSales'] = df['Quantity'] * df['UnitPrice']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerDim rows: 4338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5600\\2633493936.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Year'] = df['InvoiceDate'].dt.year\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5600\\2633493936.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Month'] = df['InvoiceDate'].dt.month\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5600\\2633493936.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Day'] = df['InvoiceDate'].dt.day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeDim rows: 17282\n",
      "SalesFact rows (last year): 0\n",
      "Data loaded into retail_dw.db\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Full ETL Function\n",
    "# -----------------------------\n",
    "def etl_pipeline(filepath):\n",
    "    df = extract_data(filepath)\n",
    "    sales_fact, customer_dim, time_dim = transform_data(df)\n",
    "    load_data(sales_fact, customer_dim, time_dim)\n",
    "\n",
    "# -----------------------------\n",
    "# Run ETL\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "     etl_pipeline(\"C:/Users/user/DSA2040_End_Sem/Online_Retail.csv\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
